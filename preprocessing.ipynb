{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "sentence_folder_path = \"data/sentences_new\"\n",
    "processed_data_folder_path = \"processed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_to_binary_sentence_data(data_folder_path,processed_data_folder_path,\n",
    "                                    data_binary_name=\"data\", data_dump_limit=100000,\n",
    "                                    data_count_limit = 99999999,verbose=1):\n",
    "    # data count limit is how many txt files do you want in total\n",
    "    # data dump limit is every how many txt files do you want to do a binary dump\n",
    "    start_time = time.time()\n",
    "    # for test purposes, data limit can be set to indicate how much data to use\n",
    "    data_count = 0\n",
    "    # give the circuit court main folder's path, read all data\n",
    "    folder_names = os.listdir(data_folder_path)\n",
    "    \n",
    "#   judge_df = pandas.DataFrame(columns=[\"Judge_Name\",\"Year\",\"Sentence\"])\n",
    "    data_list = []\n",
    "    save_part_index = 0\n",
    "    \n",
    "    for folder_name in folder_names: # for each folder\n",
    "        if verbose > 0:\n",
    "            print(\"now process:\",folder_name,\"current data count:\",data_count,\"time used:\",time.time()-start_time)\n",
    "        \n",
    "        year = folder_name[-4:]\n",
    "        data_file_names = os.listdir(os.path.join(data_folder_path,folder_name))\n",
    "        for file_name in data_file_names: # for each file\n",
    "            file_name_tokens = file_name.split(\".\")\n",
    "            file_name_tokens = file_name_tokens[0].split(\"_\")\n",
    "            judge_name = file_name_tokens[2] # we get the judge's name from the file name\n",
    "            \n",
    "            file_path = os.path.join(data_folder_path,folder_name,file_name)\n",
    "            fpt = open(file_path,\"r\")\n",
    "            sentence = fpt.read()\n",
    "            fpt.close()\n",
    "            \n",
    "            new_data_entry = [year,judge_name,sentence]\n",
    "            data_list.append(new_data_entry)\n",
    "            \n",
    "            data_count += 1\n",
    "            \n",
    "            if data_count>10 and (data_count+1)%data_dump_limit==0:\n",
    "                print(\"dumped part\",save_part_index,\"time used:\",time.time()-start_time)\n",
    "                pickle.dump(data_list, open(os.path.join(processed_data_folder_path,\n",
    "                                                    data_binary_name+str(save_part_index)), \"wb\"))\n",
    "                save_part_index += 1\n",
    "                data_list = []\n",
    "            if data_count > data_count_limit: # for debugging purposes\n",
    "                return data_count\n",
    "    \n",
    "    if data_count>10 and not (data_count+1)%data_dump_limit==0: # if have final part then dump final part\n",
    "                print(\"dumped part\",save_part_index,\"time used:\",time.time()-start_time)\n",
    "                pickle.dump(data_list, open(os.path.join(processed_data_folder_path,\n",
    "                                                    data_binary_name+str(save_part_index)), \"wb\"))\n",
    "    \n",
    "    return data_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# total data is around 450,000, of total size about 6GB\n",
    "# convert_to_binary_sentence_data(sentence_folder_path,processed_data_folder_path,verbose=1,\n",
    "#                                 data_dump_limit=50,data_count_limit = 210)\n",
    "\n",
    "convert_to_binary_sentence_data(sentence_folder_path,processed_data_folder_path,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_data = pickle.load(open(\"processed_data/data0.p\", \"rb\"))\n",
    "data_df = pandas.DataFrame(processed_data,columns=[\"year\",\"judge_name\",\"sentence\"])\n",
    "data_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
